{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "\n",
    "import pytesseract \n",
    "from pytesseract import Output\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No label found for Can-20Someone-20Really-20Steal-20Your-20Info-20From-20Your_yythkg-20-2-_jpg.rf.d844dd9d6bc2fe61dfd04bb812dd5ef1.jpg - Can-20Someone-20Really-20Steal-20Your-20Info-20From-20Your_yythkg-20-2-_jpg.rf.d844dd9d6bc2fe61dfd04bb812dd5ef1.txt\n",
      "Warning: No label found for 81-800px-NEW_YORK_1980-86_LICENSE_PLATE_0000-AAA_FORMAT_-_Flickr_-_woody1778a_jpg.rf.7ac5689098b2b2166e7e522cffec6175.jpg - 81-800px-NEW_YORK_1980-86_LICENSE_PLATE_0000-AAA_FORMAT_-_Flickr_-_woody1778a_jpg.rf.7ac5689098b2b2166e7e522cffec6175.txt\n",
      "Warning: No label found for Cheap-20automatic-20license-20plate-20readers-20are-20creeping_jpeg_jpg.rf.346502d6f95b969ad73c23dc57766fa6.jpg - Cheap-20automatic-20license-20plate-20readers-20are-20creeping_jpeg_jpg.rf.346502d6f95b969ad73c23dc57766fa6.txt\n",
      "Warning: No label found for Car-20License-20Plate-20designs_-20themes_-20templates-20and-20do_png_jpg.rf.3a447e9b946836e25b0eaf144e25f5e0.jpg - Car-20License-20Plate-20designs_-20themes_-20templates-20and-20do_png_jpg.rf.3a447e9b946836e25b0eaf144e25f5e0.txt\n",
      "Warning: No label found for Car-20License-20Plate-20designs_-20themes_-20templates-20and-20do_jpg.rf.b66bbcecd15557738769b20e0562055f.jpg - Car-20License-20Plate-20designs_-20themes_-20templates-20and-20do_jpg.rf.b66bbcecd15557738769b20e0562055f.txt\n",
      "Warning: No label found for Driver-20gets-20_110-20ticket-20for-20not-20having-20front_yythkg_jpg.rf.faef28e6448dd97ca5dffe7880858922.jpg - Driver-20gets-20_110-20ticket-20for-20not-20having-20front_yythkg_jpg.rf.faef28e6448dd97ca5dffe7880858922.txt\n",
      "Warning: No label found for File_Car-20with-20export-20license-20plate-20of-20Finland-jpg-20-_jpg.rf.0d78e60aea58d60e52b7fa3abd793aab.jpg - File_Car-20with-20export-20license-20plate-20of-20Finland-jpg-20-_jpg.rf.0d78e60aea58d60e52b7fa3abd793aab.txt\n",
      "Warning: No label found for Here_s-20Why-20You-20Should-20Remove-20Your-20Car_s-20Plates_yyth_jpg.rf.385b79f2973d6601c11f0e9e96b427af.jpg - Here_s-20Why-20You-20Should-20Remove-20Your-20Car_s-20Plates_yyth_jpg.rf.385b79f2973d6601c11f0e9e96b427af.txt\n",
      "1411 images and their labels copied from E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\TrueDataset\\train/images to E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\train/images and E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\train/labels\n",
      "Warning: No label found for 83-Acapulco-2BGuerrero-2BPlaca-2BUso-2BOficial-2BH-2BAyuntamiento-2BConstitucional-2B2002-2BAU99999_jpg.rf.58ee6452c317d412207bd7513379cb6d.jpg - 83-Acapulco-2BGuerrero-2BPlaca-2BUso-2BOficial-2BH-2BAyuntamiento-2BConstitucional-2B2002-2BAU99999_jpg.rf.58ee6452c317d412207bd7513379cb6d.txt\n",
      "Warning: No label found for All-2050-20U-S-20license-20plates_-20ranked-20from-20best_yythkg-20-1-_jpg.rf.61692b03a7f0e504d65b680914eb3995.jpg - All-2050-20U-S-20license-20plates_-20ranked-20from-20best_yythkg-20-1-_jpg.rf.61692b03a7f0e504d65b680914eb3995.txt\n",
      "409 images and their labels copied from E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\TrueDataset\\valid/images to E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\valid/images and E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\valid/labels\n",
      "Warning: No label found for Japanese-20License-20Plates-20-20Custom-20Japanese-20License-20P-20-1-_jpg.rf.854b1fa522866be5ad87863af602217b.jpg - Japanese-20License-20Plates-20-20Custom-20Japanese-20License-20P-20-1-_jpg.rf.854b1fa522866be5ad87863af602217b.txt\n",
      "204 images and their labels copied from E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\TrueDataset\\test/images to E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\test/images and E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\test/labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def sample_images_with_labels(src_image_folder, src_label_folder, dest_image_folder, dest_label_folder, sample_percentage=0.2):\n",
    "    if os.path.exists(dest_image_folder):\n",
    "        shutil.rmtree(dest_image_folder)\n",
    "    os.makedirs(dest_image_folder, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(dest_label_folder):\n",
    "        shutil.rmtree(dest_label_folder)\n",
    "    os.makedirs(dest_label_folder, exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(src_image_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    sample_size = int(len(image_files) * sample_percentage)\n",
    "    sampled_files = random.sample(image_files, sample_size)\n",
    "    \n",
    "    for image_file in sampled_files:\n",
    "        src_image_path = os.path.join(src_image_folder, image_file)\n",
    "        dest_image_path = os.path.join(dest_image_folder, image_file)\n",
    "        \n",
    "        label_file = image_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
    "\n",
    "        src_label_path = os.path.join(src_label_folder, label_file)\n",
    "        dest_label_path = os.path.join(dest_label_folder, label_file)\n",
    "        \n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.copy2(src_image_path, dest_image_path)\n",
    "            shutil.copy2(src_label_path, dest_label_path)\n",
    "        else:\n",
    "            print(f\"Warning: No label found for {image_file} - {label_file}\")\n",
    "\n",
    "    print(f\"{sample_size} images and their labels copied from {src_image_folder} to {dest_image_folder} and {dest_label_folder}\")\n",
    "\n",
    "base_dir = r'E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\TrueDataset'  \n",
    "dest_base_dir = r'E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset'\n",
    "\n",
    "sample_images_with_labels(\n",
    "    os.path.join(base_dir, 'train/images'), \n",
    "    os.path.join(base_dir, 'train/labels'), \n",
    "    os.path.join(dest_base_dir, 'train/images'), \n",
    "    os.path.join(dest_base_dir, 'train/labels')\n",
    ")\n",
    "\n",
    "sample_images_with_labels(\n",
    "    os.path.join(base_dir, 'valid/images'), \n",
    "    os.path.join(base_dir, 'valid/labels'), \n",
    "    os.path.join(dest_base_dir, 'valid/images'), \n",
    "    os.path.join(dest_base_dir, 'valid/labels')\n",
    ")\n",
    "\n",
    "sample_images_with_labels(\n",
    "    os.path.join(base_dir, 'test/images'), \n",
    "    os.path.join(base_dir, 'test/labels'), \n",
    "    os.path.join(dest_base_dir, 'test/images'), \n",
    "    os.path.join(dest_base_dir, 'test/labels')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.24 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.15  Python-3.11.5 torch-2.4.1+cpu CPU (Intel Core(TM) i5-9300H 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=Dataset/FalsoDataset/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=yolo11_license_plate_detection17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolo11_license_plate_detection17\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\train\\labels... 1403 images, 2 backgrounds, 0 corrupt: 100%|██████████| 1403/1403 [00:02<00:00, 478.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\Escritorio\\Universidad\\5.- Quinto Ao\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\valid\\labels... 407 images, 0 backgrounds, 0 corrupt: 100%|██████████| 407/407 [00:00<00:00, 490.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\Escritorio\\Universidad\\5.- Quinto Ao\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\Dataset\\FalsoDataset\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolo11_license_plate_detection17\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolo11_license_plate_detection17\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      1.283      2.206       1.18         24        640: 100%|██████████| 88/88 [08:26<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:37<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.824       0.62      0.719      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.339       1.48      1.199         21        640: 100%|██████████| 88/88 [08:31<00:00,  5.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:40<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.834      0.803      0.847      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.371      1.248      1.217         17        640: 100%|██████████| 88/88 [08:29<00:00,  5.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:37<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.665      0.654       0.64      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.327      1.026      1.197         17        640: 100%|██████████| 88/88 [08:27<00:00,  5.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.85      0.766        0.8      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.318     0.9606      1.184         23        640: 100%|██████████| 88/88 [08:26<00:00,  5.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.817      0.763      0.825       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.252     0.8493      1.156         24        640: 100%|██████████| 88/88 [08:25<00:00,  5.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.924      0.824      0.891       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.258     0.8543      1.154         26        640: 100%|██████████| 88/88 [08:26<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.898      0.854        0.9      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.265     0.8038      1.152         23        640: 100%|██████████| 88/88 [08:34<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.935      0.833      0.898      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.256     0.7818      1.139         20        640: 100%|██████████| 88/88 [08:28<00:00,  5.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.978      0.826      0.913      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.215     0.7341      1.138         18        640: 100%|██████████| 88/88 [08:26<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.89      0.843      0.898      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.233     0.7271      1.117         21        640: 100%|██████████| 88/88 [08:27<00:00,  5.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.939      0.884      0.934      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G      1.201       0.69      1.104         25        640: 100%|██████████| 88/88 [08:27<00:00,  5.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.906      0.887      0.923       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.211     0.6813      1.121         18        640: 100%|██████████| 88/88 [08:26<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.939      0.896      0.933      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.146     0.6414      1.084         23        640: 100%|██████████| 88/88 [08:27<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.932      0.863      0.925      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.175     0.6627      1.108         19        640: 100%|██████████| 88/88 [08:30<00:00,  5.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.96       0.91      0.933      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.184     0.6492      1.103         21        640: 100%|██████████| 88/88 [08:27<00:00,  5.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.954      0.904      0.929      0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.164     0.6266      1.092         29        640: 100%|██████████| 88/88 [08:27<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.954      0.913      0.941      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.139      0.623      1.092         14        640: 100%|██████████| 88/88 [08:26<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.94      0.906      0.942      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.131     0.6041      1.077         29        640: 100%|██████████| 88/88 [08:27<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.949      0.898       0.93      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.117     0.5876      1.074         20        640: 100%|██████████| 88/88 [08:27<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.963      0.907      0.938       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.108     0.5418      1.096         11        640: 100%|██████████| 88/88 [08:22<00:00,  5.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:37<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.947      0.912      0.942      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.103     0.5329      1.084         12        640: 100%|██████████| 88/88 [08:32<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:37<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.96        0.9       0.94      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.079     0.5183      1.074         12        640: 100%|██████████| 88/88 [08:32<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:37<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.97      0.912      0.948      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.095     0.5165      1.091         11        640: 100%|██████████| 88/88 [08:24<00:00,  5.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.972      0.912      0.946      0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.074     0.4948       1.08         11        640: 100%|██████████| 88/88 [08:13<00:00,  5.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.968      0.916      0.942      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G       1.06     0.4875      1.066         11        640: 100%|██████████| 88/88 [08:12<00:00,  5.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.978      0.918      0.954      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G      1.048     0.4768      1.058         11        640: 100%|██████████| 88/88 [08:12<00:00,  5.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.983      0.915      0.954      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.028      0.464      1.045         11        640: 100%|██████████| 88/88 [08:13<00:00,  5.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:35<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432       0.96      0.935      0.949      0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.021     0.4536      1.049         11        640: 100%|██████████| 88/88 [08:13<00:00,  5.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.975      0.926      0.953      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G      1.007     0.4466      1.038         11        640: 100%|██████████| 88/88 [08:21<00:00,  5.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:36<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.975      0.931      0.953      0.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 4.525 hours.\n",
      "Optimizer stripped from runs\\detect\\yolo11_license_plate_detection17\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\yolo11_license_plate_detection17\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\yolo11_license_plate_detection17\\weights\\best.pt...\n",
      "Ultralytics 8.3.15  Python-3.11.5 torch-2.4.1+cpu CPU (Intel Core(TM) i5-9300H 2.40GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:30<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        407        432      0.974      0.926      0.954      0.663\n",
      "Speed: 1.2ms preprocess, 65.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolo11_license_plate_detection17\u001b[0m\n",
      "Ultralytics 8.3.15  Python-3.11.5 torch-2.4.1+cpu CPU (Intel Core(TM) i5-9300H 2.40GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\yolo11_license_plate_detection17\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.4.1+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  3.6s, saved as 'runs\\detect\\yolo11_license_plate_detection17\\weights\\best.torchscript' (10.4 MB)\n",
      "\n",
      "Export complete (4.2s)\n",
      "Results saved to \u001b[1mE:\\Escritorio\\Universidad\\5.- Quinto Ao\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\runs\\detect\\yolo11_license_plate_detection17\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\yolo11_license_plate_detection17\\weights\\best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\yolo11_license_plate_detection17\\weights\\best.torchscript imgsz=640 data=Dataset/FalsoDataset/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Modelo entrenado guardado en: runs\\detect\\yolo11_license_plate_detection17\\weights\\best.torchscript\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "model.train(data = 'Dataset/FalsoDataset/data.yaml',\n",
    "            imgsz = 640,  \n",
    "            epochs = 30,  \n",
    "            batch = 16, \n",
    "            name = 'yolo11_license_plate_detection',\n",
    "            workers = 4)  \n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "best_weights_path = model.export()\n",
    "print(f\"Modelo entrenado guardado en: {best_weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Frame', 'Etiqueta', 'Confianza', 'X1', 'X2', 'Y1', 'Y2', 'Matrícula']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "column_colors = {\n",
    "    'Frame': 'FFCDD2',      \n",
    "    'Etiqueta': 'C8E6C9',    \n",
    "    'Confianza': 'BBDEFB',  \n",
    "    'X1': 'FFECB3',         \n",
    "    'X2': 'FFECB3',\n",
    "    'Y1': 'FFECB3',\n",
    "    'Y2': 'FFECB3',\n",
    "    'Matrícula': 'D1C4E9'    \n",
    "}\n",
    "\n",
    "def save_to_excel(frame_number, label, confidence, x1, x2, y1, y2, plate_text):\n",
    "    global df\n",
    "    \n",
    "    new_data = pd.DataFrame({\n",
    "        'Frame': [frame_number],\n",
    "        'Etiqueta': [label],\n",
    "        'Confianza': [confidence],\n",
    "        'X1': [x1],\n",
    "        'X2': [x2],\n",
    "        'Y1': [y1],\n",
    "        'Y2': [y2],\n",
    "        'Matrícula': [plate_text if label == \"License_Plate\" else \"-\"]\n",
    "    })\n",
    "    \n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "\n",
    "    with pd.ExcelWriter('detections.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='Detections')\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Detections']\n",
    "\n",
    "        for col, color in column_colors.items():\n",
    "            col_idx = df.columns.get_loc(col) + 1  \n",
    "            fill = PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "            for row in range(2, len(df) + 2): \n",
    "                worksheet.cell(row=row, column=col_idx).fill = fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 bus, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 83.1ms\n",
      "Speed: 0.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.5ms\n",
      "Speed: 0.0ms preprocess, 66.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 83.6ms\n",
      "Speed: 0.0ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.6ms\n",
      "Speed: 0.0ms preprocess, 66.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 70.1ms\n",
      "Speed: 0.0ms preprocess, 70.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 69.6ms\n",
      "Speed: 0.0ms preprocess, 69.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 88.3ms\n",
      "Speed: 0.0ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 68.3ms\n",
      "Speed: 0.0ms preprocess, 68.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 88.0ms\n",
      "Speed: 0.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 59.2ms\n",
      "Speed: 0.0ms preprocess, 59.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 62.0ms\n",
      "Speed: 2.7ms preprocess, 62.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 51.8ms\n",
      "Speed: 2.0ms preprocess, 51.8ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 68.4ms\n",
      "Speed: 12.6ms preprocess, 68.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.6ms\n",
      "Speed: 3.0ms preprocess, 64.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 113.0ms\n",
      "Speed: 3.0ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.6ms\n",
      "Speed: 0.0ms preprocess, 66.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 74.0ms\n",
      "Speed: 4.0ms preprocess, 74.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.2ms\n",
      "Speed: 3.0ms preprocess, 64.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 69.7ms\n",
      "Speed: 15.6ms preprocess, 69.7ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 70.0ms\n",
      "Speed: 0.0ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 69.7ms\n",
      "Speed: 0.0ms preprocess, 69.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 69.0ms\n",
      "Speed: 0.0ms preprocess, 69.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 59.0ms\n",
      "Speed: 0.0ms preprocess, 59.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 67.8ms\n",
      "Speed: 0.0ms preprocess, 67.8ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.7ms\n",
      "Speed: 0.0ms preprocess, 65.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 63.5ms\n",
      "Speed: 0.0ms preprocess, 63.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 61.8ms\n",
      "Speed: 4.7ms preprocess, 61.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 67.4ms\n",
      "Speed: 0.0ms preprocess, 67.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 66.7ms\n",
      "Speed: 0.0ms preprocess, 66.7ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 82.5ms\n",
      "Speed: 0.0ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 64.5ms\n",
      "Speed: 0.6ms preprocess, 64.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 79.4ms\n",
      "Speed: 0.9ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 68.9ms\n",
      "Speed: 0.0ms preprocess, 68.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 67.2ms\n",
      "Speed: 16.2ms preprocess, 67.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.7ms\n",
      "Speed: 0.0ms preprocess, 64.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 66.8ms\n",
      "Speed: 0.0ms preprocess, 66.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.9ms\n",
      "Speed: 0.0ms preprocess, 66.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 67.4ms\n",
      "Speed: 0.0ms preprocess, 67.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 138.9ms\n",
      "Speed: 3.0ms preprocess, 138.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 151.7ms\n",
      "Speed: 5.0ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 97.0ms\n",
      "Speed: 3.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 110.7ms\n",
      "Speed: 2.0ms preprocess, 110.7ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 75.1ms\n",
      "Speed: 2.1ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 License_Plate, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 83.8ms\n",
      "Speed: 2.2ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.8ms\n",
      "Speed: 2.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 80.8ms\n",
      "Speed: 1.0ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.7ms\n",
      "Speed: 3.0ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 1 License_Plate, 85.4ms\n",
      "Speed: 2.0ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 71.8ms\n",
      "Speed: 2.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 86.2ms\n",
      "Speed: 2.0ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 76.3ms\n",
      "Speed: 2.2ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 77.3ms\n",
      "Speed: 2.1ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 90.6ms\n",
      "Speed: 2.0ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 79.2ms\n",
      "Speed: 2.1ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 87.6ms\n",
      "Speed: 3.0ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 111.7ms\n",
      "Speed: 3.0ms preprocess, 111.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 68.6ms\n",
      "Speed: 2.0ms preprocess, 68.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 89.4ms\n",
      "Speed: 3.0ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 90.1ms\n",
      "Speed: 2.0ms preprocess, 90.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 86.3ms\n",
      "Speed: 3.0ms preprocess, 86.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 71.5ms\n",
      "Speed: 2.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 512x640 1 License_Plate, 74.6ms\n",
      "Speed: 2.0ms preprocess, 74.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 86.4ms\n",
      "Speed: 3.0ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 90.6ms\n",
      "Speed: 2.1ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.8ms\n",
      "Speed: 1.2ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 86.8ms\n",
      "Speed: 4.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 78.3ms\n",
      "Speed: 2.0ms preprocess, 78.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 77.5ms\n",
      "Speed: 4.0ms preprocess, 77.5ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 90.4ms\n",
      "Speed: 3.0ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 88.3ms\n",
      "Speed: 4.0ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 53.9ms\n",
      "Speed: 2.0ms preprocess, 53.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 88.8ms\n",
      "Speed: 2.0ms preprocess, 88.8ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 88.4ms\n",
      "Speed: 4.0ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 85.8ms\n",
      "Speed: 2.0ms preprocess, 85.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 1 License_Plate, 75.7ms\n",
      "Speed: 4.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 83.7ms\n",
      "Speed: 0.0ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 1 License_Plate, 100.0ms\n",
      "Speed: 3.5ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.4ms\n",
      "Speed: 2.5ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 1 License_Plate, 85.0ms\n",
      "Speed: 3.4ms preprocess, 85.0ms inference, 0.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 1 License_Plate, 85.8ms\n",
      "Speed: 2.6ms preprocess, 85.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 61.3ms\n",
      "Speed: 2.0ms preprocess, 61.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 1 License_Plate, 81.9ms\n",
      "Speed: 5.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 56.3ms\n",
      "Speed: 3.1ms preprocess, 56.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 85.1ms\n",
      "Speed: 4.6ms preprocess, 85.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 118.6ms\n",
      "Speed: 4.0ms preprocess, 118.6ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 59.1ms\n",
      "Speed: 2.0ms preprocess, 59.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 86.3ms\n",
      "Speed: 2.0ms preprocess, 86.3ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.5ms\n",
      "Speed: 3.2ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 1 License_Plate, 85.3ms\n",
      "Speed: 3.2ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 1 License_Plate, 92.7ms\n",
      "Speed: 3.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 60.1ms\n",
      "Speed: 2.0ms preprocess, 60.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 544x640 (no detections), 88.7ms\n",
      "Speed: 3.4ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 59.0ms\n",
      "Speed: 2.2ms preprocess, 59.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 84.3ms\n",
      "Speed: 4.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 95.9ms\n",
      "Speed: 6.0ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 93.6ms\n",
      "Speed: 5.0ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.7ms\n",
      "Speed: 0.9ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 86.6ms\n",
      "Speed: 4.0ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 56.0ms\n",
      "Speed: 2.0ms preprocess, 56.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 576x640 (no detections), 89.0ms\n",
      "Speed: 2.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 58.8ms\n",
      "Speed: 1.0ms preprocess, 58.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 115.1ms\n",
      "Speed: 4.8ms preprocess, 115.1ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 87.8ms\n",
      "Speed: 5.0ms preprocess, 87.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.0ms\n",
      "Speed: 3.1ms preprocess, 64.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 95.2ms\n",
      "Speed: 5.0ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.1ms\n",
      "Speed: 2.2ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.4ms\n",
      "Speed: 2.0ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 83.3ms\n",
      "Speed: 3.0ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 608x640 (no detections), 83.2ms\n",
      "Speed: 3.0ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    }
   ],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_vehicles = YOLO('yolo11n.pt').to(torch.device(\"cpu\"))\n",
    "model_license_plate = YOLO(r'runs\\detect\\yolo11_license_plate_detection17\\weights\\best.pt').to(torch.device(\"cpu\"))\n",
    "\n",
    "video_path = r'E:\\Escritorio\\Universidad\\5.- Quinto Año\\Primer Cuatrimestre\\Vision de los Computadores\\Practica\\Practica 4\\Entregable\\C0142.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "#output_path = 'output_video.mp4'\n",
    "\n",
    "#fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "CONF_THRESHOLD = 0.4\n",
    "SIZE_THRESHOLD_CARS = 5500\n",
    "SIZE_THRESHOLD_OTHERS = 2500\n",
    "\n",
    "def get_color_for_class(class_index):\n",
    "    np.random.seed(class_index)\n",
    "    return tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "def extract_text_from_plate(plate_frame):\n",
    "    base_dpi = 72\n",
    "    target_dpi = 288\n",
    "\n",
    "    scale_factor = target_dpi / base_dpi\n",
    "    new_dimensions = (int(plate_frame.shape[1] * scale_factor), int(plate_frame.shape[0] * scale_factor))\n",
    "\n",
    "    plate_frame = cv2.resize(plate_frame, new_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray_plate = cv2.cvtColor(plate_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_plate = cv2.equalizeHist(gray_plate)\n",
    "\n",
    "    adjusted_plate = cv2.convertScaleAbs(gray_plate, alpha=1.5, beta=50)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "\n",
    "    adjusted_plate = cv2.dilate(adjusted_plate, kernel, iterations=1)\n",
    "    adjusted_plate = cv2.erode(adjusted_plate, kernel, iterations=1)\n",
    "\n",
    "    custom_config = r'--psm 7 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "\n",
    "    plate_text = pytesseract.image_to_string(adjusted_plate, config=custom_config).strip()\n",
    "    return plate_text\n",
    "\n",
    "def detect_license_plate(vehicle_frame):\n",
    "\n",
    "    plate_results = model_license_plate(vehicle_frame)\n",
    "    plate_text = \"\"\n",
    "\n",
    "    for r in plate_results:\n",
    "        for box in r.boxes:\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = box.conf[0]\n",
    "            if conf > 0.4:\n",
    "                plate_frame = vehicle_frame[y1:y2, x1:x2]\n",
    "                plate_text = extract_text_from_plate(plate_frame)\n",
    "                label_text = f\"LP: {plate_text}\"\n",
    "\n",
    "                cv2.rectangle(vehicle_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(vehicle_frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                #save_to_excel(frame_number, \"License_Plate\", conf, x1, x2, y1, y2, plate_text)\n",
    "\n",
    "    return vehicle_frame\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model_vehicles.track(source=frame, persist=True)\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            conf = box.conf[0]\n",
    "            label = model_vehicles.names[cls]\n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "            if label in [\"car\", \"bus\"]:\n",
    "                if conf < CONF_THRESHOLD or area < SIZE_THRESHOLD_CARS:\n",
    "                    continue\n",
    "            else:\n",
    "                if conf < CONF_THRESHOLD or area < SIZE_THRESHOLD_OTHERS:\n",
    "                    continue\n",
    "\n",
    "            if label in [\"car\", \"motobicycle\", \"bus\"]:\n",
    "                vehicle_frame = frame[y1:y2, x1:x2]\n",
    "                vehicle_frame_with_plate = detect_license_plate(vehicle_frame)\n",
    "                frame[y1:y2, x1:x2] = vehicle_frame_with_plate\n",
    "\n",
    "            color = get_color_for_class(cls)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            #save_to_excel(frame_number, label, conf, x1, x2, y1, y2, \"-\")\n",
    "        \n",
    "        frame_number += 1\n",
    "\n",
    "    scaled_frame = cv2.resize(frame, (0, 0), fx=0.6, fy=0.6)\n",
    "    cv2.imshow(\"Detección de Vehículos y Matrículas\", scaled_frame)\n",
    "\n",
    "    #out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
